# Text Vectorization Repository

This repository contains a Jupyter notebook with implementations of text vectorization techniques, including Bag of Words, TF-IDF, and Word2Vec. These techniques are widely used in natural language processing (NLP) tasks to convert textual data into numerical representations, enabling machine learning algorithms to process and analyze text.

## Notebook Structure

```
- imdb_movies_review.ipynb
- IMDB Dataset/
  - README.txt
```

- `imdb_movies_review.ipynb`: Jupyter notebook containing the implementation of the text vectorization techniques.
- `IMDB Dataset/`: Directory containing data for training.

## Text Vectorization Techniques

### Bag of Words

The Bag of Words (BoW) technique represents text as a collection of word frequencies. It creates a vocabulary of all unique words in the corpus and counts the number of occurrences of each word in each document. The resulting vectors can be sparse, with each dimension representing a word and its value representing the frequency or presence of the word in the document. Bag of Words is a simple and effective technique but doesn't capture the ordering of words or their semantic relationships.

### TF-IDF

Term Frequency-Inverse Document Frequency (TF-IDF) is a widely used text vectorization technique. It calculates the importance of each word in a document within a larger collection of documents. The vectors capture both local information (term frequency) and global information (inverse document frequency). This technique assigns higher weights to words that are more informative and discriminative across the entire corpus. TF-IDF is useful for capturing the importance of words in a document while also downweighting frequently occurring words that may not carry much discriminatory power.

### Word2Vec

Word2Vec is a neural network-based technique that learns continuous vector representations of words. It captures semantic and syntactic relationships between words, enabling vector arithmetic operations like word analogies. Word2Vec models can be trained on large unlabeled text corpora to create dense, fixed-size vectors for each word. The vectors generated by Word2Vec represent the meaning of words in a high-dimensional space. This technique is particularly effective at capturing semantic similarities and relationships between words.

## Usage

1. Clone the repository:

   ```shell
   git clone https://github.com/your-username/Text-Vectorization.git
   cd Text-Vectorization
   ```

2. Open the `imdb_movies_review.ipynb` notebook in Jupyter or any compatible environment.

3. Follow the instructions and code snippets in the notebook to explore and use the text vectorization techniques.

4. The notebook provides examples of how to use Bag of Words, TF-IDF, and Word2Vec techniques on sample text data. You can modify the code and adapt it to your specific use case.

5. The `data/sample_text.txt` file contains a small sample text that you can use for testing the vectorization techniques. You can replace it with your own text data or use additional datasets as needed.

## Dependencies

The notebook requires the following dependencies:

- Python 3.x
- Jupyter Notebook
- scikit-learn
- gensim (for Word2Vec)

Make sure you have these dependencies installed before running the notebook.

## Contributing

Contributions to this repository are welcome. If you find any issues or have suggestions for improvement, please open an issue or submit a pull request.

## License

The code in this repository is licensed under the [MIT License](LICENSE). Feel free to use and modify the code for your own projects.
